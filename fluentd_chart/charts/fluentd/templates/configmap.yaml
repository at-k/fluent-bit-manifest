apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-env
  labels:
    app: {{ .Release.Name }}
type: Opaque
data:
{{ toYaml .Values.env | indent 2 }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "fluentd.fullname" . }}
  labels:
{{ include "fluentd.labels" . | indent 4 }}
data:
  fluent.conf: |
    @include "#{ENV['FLUENTD_SYSTEMD_CONF'] || 'systemd'}.conf"
    @include "#{ENV['FLUENTD_PROMETHEUS_CONF'] || 'prometheus'}.conf"
    @include kubernetes.conf
    @include conf.d/*.conf

    <source>
      @type forward
    </source>

    <match kubernetes.var.log.containers.**fluentd**.log>
      @type null
    </match>

    <filter kubernetes.**>
      @type concat
      key log
      multiline_end_regexp /\n$/
    </filter>

    # create temporary metadata for tag
    <filter kubernetes.**>
      @type record_transformer
      enable_ruby true
      <record>
        s3_log_path ${"#{ENV['S3_ROOT']}" + "." + record["kubernetes"]["namespace_name"] + "." + record["kubernetes"]["container_name"] + "." + record["kubernetes"]["pod_name"]}
      </record>
    </filter>

    # tag transform
    # original tag: kubernetes.var.log.containers.<pod_name>_<namespace>_<filename>.log
    # after: kube.<s3_top_path>.<namespce>.<contaienr_name>
    <match kubernetes.**>
      @type rewrite_tag_filter
      <rule>
        key $['s3_log_path']
        pattern ^(.+)$
        tag modified.$1
      </rule>
    </match>

    <filter modified.**>
      @type parser
      format json
      key_name log
      reserve_data true
      emit_invalid_record_to_error false
      hash_value_field parsed
    </filter>

    <match modified.**>
      @type copy
      # <store>
      #   @type stdout
      #   include_tag_key true
      # </store>
      <store>
        @type s3
        @id out_s3
        @log_level info
        s3_region ap-northeast-1
        s3_bucket "#{ENV['S3_BUCKET_NAME']}"
        s3_object_key_format %{path}%{time_slice}_${tag[4]}_%{index}.%{file_extension}
        path ${tag[1]}/${tag[2]}/${tag[3]}/

        time_slice_format     %Y/%m/%d/%H
        flush_interval        1m

        <inject>
          time_key time
          tag_key tag
          localtime false
        </inject>
        <buffer tag,time>
          @type file
          path /var/log/fluentd-buffers/s3.buffer
          timekey 3600
          timekey_use_utc true
          chunk_limit_size 256m
        </buffer>
        <format>
          @type json
        </format>
      </store>
      <store>
        @type elasticsearch
        @id out_es
        @log_level info
        include_tag_key true
        host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
        port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
        path "#{ENV['FLUENT_ELASTICSEARCH_PATH']}"
        scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
        ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY'] || 'true'}"
        ssl_version "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERSION'] || 'TLSv1_2'}"
        reload_connections "#{ENV['FLUENT_ELASTICSEARCH_RELOAD_CONNECTIONS'] || 'false'}"
        reconnect_on_error "#{ENV['FLUENT_ELASTICSEARCH_RECONNECT_ON_ERROR'] || 'true'}"
        reload_on_failure "#{ENV['FLUENT_ELASTICSEARCH_RELOAD_ON_FAILURE'] || 'true'}"
        log_es_400_reason "#{ENV['FLUENT_ELASTICSEARCH_LOG_ES_400_REASON'] || 'false'}"
        logstash_prefix "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX'] || 'logstash'}"
        logstash_format "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_FORMAT'] || 'true'}"
        index_name "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_INDEX_NAME'] || 'logstash'}"
        type_name "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_TYPE_NAME'] || 'fluentd'}"
        <buffer>
          flush_thread_count "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_THREAD_COUNT'] || '8'}"
          flush_interval "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_INTERVAL'] || '30s'}"
          chunk_limit_size "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_CHUNK_LIMIT_SIZE'] || '10M'}"
          queue_limit_length "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_QUEUE_LIMIT_LENGTH'] || '32'}"
          retry_max_interval "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_RETRY_MAX_INTERVAL'] || '30'}"
          retry_forever true
        </buffer>
      </store>
    </match>
